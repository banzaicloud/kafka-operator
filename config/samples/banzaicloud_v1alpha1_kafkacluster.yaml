apiVersion: banzaicloud.banzaicloud.io/v1alpha1
kind: KafkaCluster
metadata:
  labels:
    controller-tools.k8s.io: "1.0"
  name: kafka
spec:
  # Specify the zookeeper addresses where the Kafka should store it's metadata
  zkAddresses:
    - "example-zookeepercluster-client.zookeeper:2181"
  # Specify the Kafka Broker related settings
  # All Broker requires an image, unique id, and storageConfigs settings
  brokerConfigs:
    # Docker image used by the operator to create the Broker with id 0
    - image: "wurstmeister/kafka:2.12-2.1.0"
      # Unique broker id which is used as kafka config broker.id
      id: 0
      # nodeAffinity can be specified, operator populates this value if new pvc added later to brokers
      # nodeAffinity:
      # config parameter can be used to pass any Kafka config https://kafka.apache.org/documentation/#brokerconfigs
      # expect listener specific configs, security based configs, log dir related configs
      # config:`
      #delete.topic.enable=true
      #auto.create.topics.enable=true
      #`
      # storageConfigs specifies the broker log related configs
      storageConfigs:
        # mountPath will be used in kafka config log.dirs so it must be unique
        - mountPath: "/kafka-logs"
          # pvcSpec describes the PVC used for the mountPath described above
          # it requires a kubernetes PVC spec
          pvcSpec:
            accessModes:
              - ReadWriteOnce
            # storageClassName: standard
            resources:
              requests:
                storage: 10Gi
        #- mountPath: "/kafka-second-log-volume"
        #    pvcSpec:
        #      accessModes:
        #        - ReadWriteOnce
        #      resources:
        #        requests:
        #          storage: 3Gi
    - image: "wurstmeister/kafka:2.12-2.1.0"
      id: 1
      storageConfigs:
        - mountPath: "/kafka-logs"
          pvcSpec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 10Gi
    - image: "wurstmeister/kafka:2.12-2.1.0"
      id: 2
      storageConfigs:
        - mountPath: "/kafka-logs"
          pvcSpec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 10Gi
    - image: "wurstmeister/kafka:2.12-2.1.0"
      id: 3
      storageConfigs:
        - mountPath: "/kafka-logs"
          pvcSpec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 10Gi
  # listenersConfig specifies kafka's listener specific configs
  listenersConfig:
    # externalListeners specifies settings required to access kafka externally
    externalListeners:
      # type defines the used security type ssl, plaintext are the two supported ones
      - type: "ssl"
        # Kafka enables to name your listeners
        name: "external"
        # Operator uses a single LoadBalancer and an Envoy proxy to enable external access
        # to differentiate between brokers we are using ports, with externalStartingPort
        # the user can specify the starting port where the first broker will be available
        externalStartingPort: 19090
        # containerPort describes what port should be used by the broker to handle the communication
        # originates from outside of the cluster
        containerPort: 9094
    # internalListeners specifies settings required to access kafka externally
    internalListeners:
      # type defines the used security type ssl, plaintext are the two supported ones
      - type: "ssl"
        # Kafka enables to name your listeners because of a bug only ssl and plaintext can be used
        name: "ssl"
        # containerPort describes what port should be used by the broker to handle the communication
        # originates from inside of the cluster
        containerPort: 29092
        # Support for multiple internal and external listeners are coming soon this value tells the operator which
        # internal listener configuration must be used for broker to broker communication
        usedForInnerBrokerCommunication: true
    # sslSecrets contains information about ssl related kubernetes secrets if one of the
    # listener setting type set to ssl these fields must be populated too.
    sslSecrets:
      # tlsSecretName should contain all ssl certs required by kafka including: caCert, caKey, clientCert, clientKey
      # serverCert, serverKey, peerCert, peerKey
      tlsSecretName: "test-kafka-operator"
      # jksPasswordName should contain a password field which contains the jks password
      jksPasswordName: "test-kafka-operator-pass"
  # Specify the ServiceAccount where the Kafka Pods and the Cruise Control is running
  serviceAccount: ""
